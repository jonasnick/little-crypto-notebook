\subsection{Prove Multiplication in ZK}

\begin{equation*}
  \mathcal{R}_{\textrm{mult}} = \{ ((G_0, G_1, H \in \mathbb{G}), (V, C \in \mathbb{G})) , (a, b, s_C, s_V \in \mathbb{Z}_p))  | V = abG_0 + s_VH, C = aG_0 + bG_1 + s_CH\}
\end{equation*}

\begin{enumerate}
\item Prover draws $s_a, s_b, s_S, \tau_1, \tau_2$ sends
  \begin{align*}
    S &= s_aG_0 + s_b G_1 + s_S H\\
    T_1 &= (as_b + bs_a)G_0 + \tau_1H\\
    T_2 &= s_as_bG_0 + \tau_2H\\
  \end{align*}
  \item Verifier sends random challenge $x$
  \item Prover sends
  \begin{align*}
    l = l(x) &= a + s_ax\\
    r = r(x) &= b + s_bx\\
    \mu &= s_C + xs_S\\
    \tau_x &= s_v + x\tau_1 + x^2\tau_2
  \end{align*}
  \item Verifier checks
    \begin{align*}
      C + xS &= lG_0 + rG_1 + \mu H\\
      V + xT_1 + x^2T_2 &= lrG_0 + \tau_x H \\
    \end{align*}
\end{enumerate}

\subsubsection{Correctness}
\begin{align*}
  C + xS &= aG_0 + bG_1 + s_CH + x(s_aG_0 + s_b G_1 + s_SH)\\
         &= (a + xs_a)G_0 + (b + xs_b)G_1 + (s_C + xs_S)H\\
         &= lG_0 + rG_1 + \mu H\\
\end{align*}
\begin{align*}
  V + xT_1 + x^2T_2 &= abG_0 + s_vH+ x(as_b + bs_a)G_0 + x\tau_1H + x^2s_as_bG_0 + x^2\tau_2H\\
                    &= (ab + x(as_b + bs_a) + x^2s_as_b)G_0 + (s_v + x\tau_1 + x^2\tau_2)H\\
                    &= lrG_0 + \tau_xH
\end{align*}

\subsubsection{Extension to vectors}
\todo[inline]{Actually it's not that easy. The verifier needs to send $\rho$ before the prover can send the error terms because they need to account for $\rho$.}
Note that if $a$ and $b$ were vectors $\vec{a}, \vec{b} \in \Z_p^n$, $C$ was a commitment to these vectors and $V = \ip{\vec{a}}{\vec{b}}G_0 + s_VH$, then it would be possible to avoid sending vectors $\vec{l}$ and $\vec{r}$ using the inner product argument.
To do that, the verifier sends challenge $\rho$ along with $x$.
Then the prover replies $\hat{t} = \ip{\vec{l}}{\vec{r}}_{\rho}$ (weighted inner product) instead of $\vec{l}, \vec{r}$. The verifer then checks
\begin{align*}
  V + xT_1 + x^2T_2 &= \hat{t}G_0 + \tau_x H \\
\end{align*}
and both prover and verifier run the weighted inner product argument on $C + xS + \hat{t}yG_2 - \mu H$ for a fresh challenge $y$.

\subsubsection{Perfect Honest Verifier Zero Knowledge}

\paragraph{Proof sketch}
\begin{enumerate}
  \item Simulator draws random $l, r, \mu, \tau_x, T_2$. And since we're proving honest verifier ZK, the simulator draws random $x$.
  \item Simulator sets $S = \frac{1}{x}(lG_0 + rG_1 + \mu H - C)$
  \item Simulator sets $T_1 = \frac{1}{x}(lrG_0 + \tau_xH - V - x^2T_2$)
\end{enumerate}
All elements in the proof are either independently randomly distributed or their relationship is fully defined by the verification equations.
The simulator is efficient.

\paragraph{Variants of the Protocol that are not (Perfect) HVZK}
Note that in our definition of HVZK, the adversary comes up with the statement and the witness.
A ZK proof like the one above seems tricky because these variants don't obviously look (to me) like they violate the proof.

\begin{itemize}
  \item Can't we just remove $s_a$ from the protocol, i.e., the prover sends $l = l(x) = a$? No, even if the simulator is able to make the verification equations work for some $l$ drawn at random, the adversary knows the actual witness and easily notices that $l \ne a$.
  \item Can't we just remove $s_S$ from the protocol, i.e., the prover sends $\mu = s_C$? No, the same reason why we can't remove $s_a$ applies as $s_C$ is also a witness..
  \item Can't we remove $\tau_2$ from the protocol, i.e., the prover sets $T_2 = s_as_bG_0$? No, that would allow the adversary to compute $s_m$ from $T_2 = s_mG_0$. The adversary can also compute $s_a$ from $l$ and $s_b$ from $r$ and it will see that $s_as_b \ne s_m$.
\end{itemize}

\begin{theorem}
  Above protocol for $\mathcal{R}_{\textrm{mult}}$ has perfect HVZK.
\end{theorem}
\begin{pproof}
  \step{1}{It suffices to give a simulator that outputs a transcript $\pi = (x, l, r, \mu, \tau_x, S, T_1, T_2)$ such that the probability distribution $\Pr(\pi' = \pi)$ for random variable $\pi'$ is equal to the probability distribution of an accepting transcript for a correct statement between a prover and honest verifier.
           To simplify the notation, we write $\Pr(\pi' = \pi)$ as $\Pr(\pi)$.}
  \step{2}{ Let $\mathcal{S}$ be a simulator which draws $x, l, r, \mu, \tau_x, T_2$ uniformly at random and sets
    \begin{align*}
      S &:= \frac{1}{x}(lG_0 + rG_1 + \mu H - C)\\
      T_1 &:= \frac{1}{x}(lrG_0 + \tau_xH - V - x^2T_2)
    \end{align*}
    The simulator is efficient.}
  \step{3}{ The distribution of transcript $\pi$ output by the simulator is
    \begin{align*}
        \Pr(\pi) &= \Pr(x, l, r, \mu, \tau_x, S, T_1, T_2)\\
                        &= \begin{cases} 0 \text{ if } S \ne \frac{1}{x}(lG_0 + rG_1 + \mu H - C) \text{ or } T_1 \ne \frac{1}{x}(lrG_0 + \tau_xH - V - x^2T_2) \\
                             \Pr(x)\Pr(l)\Pr(r)\Pr(\mu)\Pr(\tau_x)\Pr(T_2) \text{ otherwise}
                             \end{cases}
    \end{align*}
    where $\Pr(x),\Pr(l),\Pr(r),\Pr(\mu),\Pr(\tau_x),\Pr(T_2)$ are uniform distributions.
    }
  \step{4}{The distribution of transcript $\pi$ in an honest interaction is
    \begin{align*}
      \Pr(\pi) &= \Pr(x) \Pr(l|x, s_a) \Pr(r|x, s_b) \Pr(\mu| x, s_S) \Pr(\tau_x| x, \tau_1, \tau_2) \Pr(S| s_a, s_b, s_S) \Pr(T_1| s_a, s_b, \tau_1)\\
      &\qquad \Pr(T_2| s_a, s_b, \tau_2) \Pr(s_a)\Pr(s_b)\Pr(s_S)\Pr(\tau_1 )\Pr(\tau_2)
    \end{align*}
    where $\Pr(x),\Pr(s_a),\Pr(s_b),\Pr(s_S),\Pr(\tau_1),\Pr(\tau_2)$ are uniform distributions and all conditional probability distributions are 0 if the defining equation holds and 1 otherwise. For example, $\Pr(l|x, s_a) = 0$ if $l\ne a + s_ax$.}
   \step{5}{We can rewrite the distribution of transcript $\pi$ in an honest interaction as
    \begin{align*}
        \Pr(\pi) &= \Pr(x, l, r, \mu, \tau_x, S, T_1, T_2)\\
                        &= \begin{cases} 0 \text{ if } S \ne s_aG_0 + s_bG_1 x^{-1}(s_C - \mu)H \text{ or } T_1 \ne (as_b + bs_a)G_0 + \tau_1H \text{ for }\\ \qquad s_a := x^{-1}(l - a), s_b := x^{-1}(r - b), \tau_1 := - x^{-1}(s_V  + x^2\tau_2 - \tau_x), \tau_2 := \log_H(T_2) - s_as_b\log_H(G_0) \\
                             \Pr(x)\Pr(l)\Pr(r)\Pr(\mu)\Pr(\tau_x)\Pr(T_2) \text{ otherwise}
                             \end{cases}
    \end{align*}
    where $\Pr(x),\Pr(l),\Pr(r),\Pr(\mu),\Pr(\tau_x),\Pr(T_2)$ are uniform distributions.
   }
   \begin{pproof}
     \step{5a}{Since $\Pr(l|x, s_a)\Pr(s_a) = \Pr(l,s_a|x) = \Pr(s_a|x, l) \Pr(l)$ and that holds similarly for $r$, $\mu$, as well as $\Pr(\tau_x| x, \tau_1, \tau_2)\Pr(\tau_1 ) = \Pr(\tau_1| x, \tau_x, \tau_2)\Pr(\tau_x )$ and $\Pr(T_2| s_a, s_b, \tau_2)\Pr(\tau_2) = \Pr(\tau_2| s_a, s_b, T_2)\Pr(T_2)$,
       we have
       \begin{align*}
      \Pr(\pi) &= \Pr(x) \Pr(s_a|x, l) \Pr(s_b|x, r) \Pr(s_S| x, \mu) \Pr(\tau_1| x, \tau_x, \tau_2) \Pr(S| s_a, s_b, s_S) \Pr(T_1| s_a, s_b, \tau_1)\\
      &\qquad \Pr(\tau_2| s_a, s_b, T_2) \Pr(l)\Pr(r)\Pr(\mu)\Pr(\tau_x )\Pr(T_2)
       \end{align*}
       }
     \step{5b}{We can rewrite this to get rid of hidden random variables $s_a, s_b, s_S, \tau_1, \tau_2$ as
       \begin{align*}
      \Pr(\pi) &= \Pr(x) \Pr(S| x, l, r, \mu) \Pr(T_1| x, l, r, \tau_x, T_2) \Pr(l)\Pr(r)\Pr(\mu)\Pr(\tau_x )\Pr(T_2).
       \end{align*}
     }
     \step{5c}{$\Pr(\pi) = 0$ if and only if $\Pr(S| x, l, r, \mu) = 0$ or $\Pr(T_1| x, l, r, \tau_x, T_2) = 0$, otherwise both probabilities are 1.}
    \end{pproof}
  \step{6}{The distributions of the honest transcript and simulated transcripts are the same.}
  \begin{pproof}
    \step{6a}{In the honest transcript we have $S = \frac{1}{x}(lG_0 + rG_1 + s_CH - (aG_0 + bG_1 + \mu H)) = \frac{1}{x}(lG_0 + rG_1 + s_CH - C)$ since the statement is valid. Similarly
      \begin{align*}
        T_1 &= (as_b + bs_a)G_0 - x^{-1}(s_V  + x^2(\log_H(T_2) - s_as_b\log_H(G_0)) - \tau_x)H\\
            &= \frac{1}{x}((xas_b + xbs_a)G_0 + \tau_xH - s_VH - x^2T_2 - x^2s_as_bG_0)\\
            &= \frac{1}{x}((xas_b + xbs_a - x^2s_as_b)G_0 + \tau_xH - s_VH - x^2T_2)\\
            &= \frac{1}{x}((lr - ab)G_0 + \tau_xH - s_VH - x^2T_2)\\
            &= \frac{1}{x}(lr G_0 + \tau_xH - V - x^2T_2)\\
      \end{align*}}
  \end{pproof}
\end{pproof}


\subsubsection{(Computational) witness extended emulation}
If there was no challenge $x$ then the verifier would check  $V + T_1 + T_2 = lrG_0 + \tau_xH$.
So the prover could choose some $a, b, \tau_x$ at random, then set $T_1 = lrG_0 + \tau_xH - V - T_2$ (similar to zero knwledge).

\begin{theorem}
  Above protocol Computational Witness Extended Emulation
\end{theorem}
\begin{pproof}
  \step{1}{It suffices to show that the emulator can extract $a,b,s_V,s_C$ such that $V = abG_0 + s_VH, C = aG_0 + bG_1 + s_CH$ or we have a discrete logarithm relation between the generators.}
  \step{2}{Using the rewinding oracle, the emulator runs the prover with three different challenges, $x_0$, $x_1$, $x_2$ which allows extracting $a, b, s_a, s_b, s_V, s_C$ and $s_S$.}
  \begin{pproof}
    \step{2a}{Need two execution to extract $a, b, s_a, s_b, s_C, s_S$ from $l_{0,1}, r_{0,1}, \mu_{0,1}$ and three executions to extract $s_V, \tau_1, \tau_2$ from $\tau_{x,0,1,2}$}
  \end{pproof}
  \step{3}{For $C = a'G_0 + b'G_1 + s_C'H$ and $S = s_a'G_0 + s_b'G_1 + s_S'H$ it holds that $a = a', b = b', s_C = s_c', s_a = s_a', s_b = s_b', s_S = s_S'$ or we have a discrete logarithm relation between the generators.}
  \begin{pproof}
    \step{3a}{We have $a' + xs_a' = a + xs_a, b' + xs_b' = b+xs_b,  s_C' + xs_S' = s_C' + xs_S'$ or a discrete logarithm relation between the generators.}
    \begin{pproof}
    \step{3a0}{Note if the prover would know the DL $d$ such that $G_1 = dG_0$ it could have sent an $l = d + a' + s_a x, r = (b'-1) + s_a x$ and then the extractor would have obtained $a = d + a', b = b' - 1$. Yet, it holds that
      \begin{align}
        lG_0 + rG_1 + \mu H &= (d + a' + s_ax)G_0 + (b'-1 + s_bx)G_1 + \mu H\\
                           &= (a' + s_ax)G_0 + (b' + s_bx)G_1 + \mu H
      \end{align}
      since $l$, $r$ are valid for $C = a'G_0 + b'G_1 + s_CH$. Then we have $a \ne a'$ and $b \ne b'$.}
    \step{3a1}{Can obtain representation $C = a'G_0+ b'G_1+ s_C'H$, $S = s_a'G_0 + s_b'G_1 + s_S'H$ from
      \begin{align}
        C + xS &= l_iG_0 + r_iG_1 + \mu_i H
      \end{align}
      as
      \begin{align}
        a' + xs_a' = l_i\\
        b' + xs_b' = r_i\\
        s_C' + xs_S' = \mu_i
      \end{align}
      }
    \step{3a3}{Then
      \begin{align}
        C + xS &= lG_0 + rG_1 + \mu H\\
        (a' + xs_a')G_0 + (b' + xs_b')G_1 + (s_C' + xs_S')H &= (a + xs_a)G_0 + (b+xs_b)G_1 + (s_C' + xs_S')H\\
      \end{align}
      }
    \step{3a3}{Now either
      \begin{align}
        a' + xs_a'&= a + xs_a\\
        b' + xs_b' &= b+xs_b\\
        s_C' + xs_S' &= s_C' + xs_S'
      \end{align}
      or the extractor has obtained a discrete logarithm relation between the generators.
      }
    \end{pproof}
    \step{3b}{The probability that $a' \ne a$ or $s_a' \ne s_a$ while $a' + xs_a' = a + xs_a$ is negligible due to the Schwartz-Zippel Lemma}
  \end{pproof}
  \step{5}{For $V = a'b'G_0 + s_V'H$ we extract $a'b' = ab$ and $s_V' = s_V$ or the extractor has found a DLog between generators.}
  \begin{pproof}
    \step{5a}{For $T_1 = t_1'G_0 + \tau_1'H,T_2 = t_2'G_0 + \tau_2'H$ it holds that
      \begin{align}
          a'b' + xt_1' + x^2t_2'&= ab + x(as_b + bs_a) + x^2s_as_b\\
          s_V' + x\tau_1H + x^2\tau_2 &= s_V + x\tau_1 + x^2\tau_2
       \end{align}
       or the extractor has found a DLog between generators.
    }
    \begin{pproof}
      \step{5a1}{We obtain $s_V', \tau_1', \tau_2'$ from
        \begin{align*}
          V + x_iT_1 + x_i^2T_2 &= l_ir_iG_0 + \tau_{x,i}H
        \end{align*}
        as
        \begin{align*}
          a'b' + x_it_1' + x_i^2t_2' &= l_ir_i\\
          s_V' + x_i\tau_1' + x_i^2\tau_2' &= \tau_{x,i}
        \end{align*}
        }
      \step{5a2}{Then it holds that
        \begin{align*}
          V + xT_1 + x^2T_2 &= lrG_0 + \tau_xH\\
          a'b'G_0 + s_V'H + x(t_1G_0 + \tau_1H)  + x^2(t_2G_0 + \tau_2H)&= (ab + x(as_b + bs_a) + x^2s_as_b)G_0 + (s_V + x\tau_1 + x^2\tau_2)H\\
          (a'b' + xt_1' + x^2t_2')G_0 + (s_V' + x\tau_1H + x^2\tau_2)H&= (ab + x(as_b + bs_a) + x^2s_as_b)G_0 + (s_V + x\tau_1 + x^2\tau_2)H\\
        \end{align*}
        which implies either equality between the scalars on the LHS and RHS or the extractor has obtained the DLog between generators.
      }
    \end{pproof}
    \step{5b}{It holds that $a'b' = ab$ and $s_V' = s_V$ per the Schwartz-Zippel Lemma}
  \end{pproof}
\end{pproof}

